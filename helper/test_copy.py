import pandas as pd
import openpyxl
from openpyxl.worksheet.worksheet import Worksheet
from collections import deque
from typing import List, Dict, Set, Tuple, Any
import numpy as np
import json


# ======================================================================
# GIAI ƒêO·∫†N 1: PH√ÅT HI·ªÜN B·∫¢NG (Gi·ªØ nguy√™n t·ª´ tr∆∞·ªõc)
# ======================================================================

# --- B∆Ø·ªöC 1: T·∫†O B·∫¢N ƒê·ªí TRA C·ª®U √î G·ªòP ---
def _create_merged_cell_map(ws: Worksheet) -> Dict[Tuple[int, int], Tuple[int, int]]:
    """
    T·∫°o m·ªôt dict (map) ƒë·ªÉ tra c·ª©u √¥ "cha" (√¥ top-left ch·ª©a style)
    t·ª´ b·∫•t k·ª≥ t·ªça ƒë·ªô √¥ "con" n√†o.
    
    Returns:
        Dict[(con_r, con_c), (cha_r, cha_c)]
    """
    merged_map = {}
    # L·∫∑p qua t·∫•t c·∫£ c√°c d·∫£i √¥ g·ªôp trong sheet
    for merged_range in ws.merged_cells.ranges:
        # L·∫•y t·ªça ƒë·ªô (1-based index) c·ªßa d·∫£i √¥
        min_col, min_row, max_col, max_row = merged_range.bounds
        
        # T·ªça ƒë·ªô √¥ "cha" (√¥ top-left)
        parent_coord = (min_row, min_col)
        
        # L·∫∑p qua t·∫•t c·∫£ √¥ "con" trong d·∫£i (bao g·ªìm c·∫£ √¥ cha)
        for r in range(min_row, max_row + 1):
            for c in range(min_col, max_col + 1):
                # √Ånh x·∫° √¥ con v·ªÅ √¥ cha
                merged_map[(r, c)] = parent_coord
    return merged_map

# --- B∆Ø·ªöC 2: T·∫†O B·∫¢N ƒê·ªí NHI·ªÜT BORDER (ƒê√É X·ª¨ L√ù √î G·ªòP) ---
def _create_border_heatmap(ws: Worksheet, merged_map: Dict) -> List[List[bool]]:
    """
    T·∫°o m·ªôt b·∫£n ƒë·ªì 2D (heatmap) c·ªßa sheet.
    True = "ƒê·∫•t" (√î n√†y c√≥ border, ho·∫∑c l√† 1 ph·∫ßn c·ªßa √¥ g·ªôp c√≥ border)
    False = "Bi·ªÉn" (√î n√†y kh√¥ng c√≥ border)
    
    B·∫£n ƒë·ªì n√†y s·ª≠ d·ª•ng 0-based index ƒë·ªÉ d·ªÖ d√†ng cho B∆∞·ªõc 3.
    """
    max_r, max_c = ws.max_row, ws.max_column
    
    # T·∫°o b·∫£n ƒë·ªì r·ªóng (0-indexed)
    # heatmap[h√†ng][c·ªôt]
    heatmap = [[False for _ in range(max_c)] for _ in range(max_r)]

    # L·∫∑p qua t·ª´ng √¥ trong sheet (1-indexed)
    for r in range(1, max_r + 1):
        for c in range(1, max_c + 1):
            
            # 1. T√¨m t·ªça ƒë·ªô √¥ ch·ª©a style
            # M·∫∑c ƒë·ªãnh l√† ch√≠nh n√≥
            style_coord = (r, c)
            if (r, c) in merged_map:
                # N·∫øu l√† √¥ con, l·∫•y t·ªça ƒë·ªô √¥ cha
                style_coord = merged_map[(r, c)]
            
            # 2. L·∫•y √¥ style t·ª´ t·ªça ƒë·ªô
            style_cell = ws.cell(row=style_coord[0], column=style_coord[1])
            
            # 3. Ki·ªÉm tra border c·ªßa √¥ style
            b = style_cell.border
            # Ch·ªâ c·∫ßn 1 c·∫°nh c√≥ style l√† coi nh∆∞ √¥ ƒë√≥ c√≥ border
            if (b.left.style or b.right.style or b.top.style or b.bottom.style):
                # ƒê√°nh d·∫•u "ƒê·∫•t" (True) v√†o heatmap (0-indexed)
                heatmap[r-1][c-1] = True
                
    return heatmap

# --- B∆Ø·ªöC 3: T√åM "C·ª§M BORDER" (BFS) ---
def _find_clusters(heatmap: List[List[bool]]) -> List[List[Tuple[int, int]]]:
    """
    Ch·∫°y thu·∫≠t to√°n BFS (Breadth-First Search) tr√™n heatmap
    ƒë·ªÉ t√¨m c√°c "qu·∫ßn ƒë·∫£o" (c·ª•m) c√°c √¥ "ƒê·∫•t" (True) li·ªÅn k·ªÅ nhau.
    
    Returns:
        List c√°c c·ª•m, m·ªói c·ª•m l√† 1 List c√°c t·ªça ƒë·ªô (r, c) (0-indexed).
    """
    if not heatmap: 
        return []
        
    rows = len(heatmap)
    cols = len(heatmap[0])
    
    visited = set()  # Set ch·ª©a c√°c t·ªça ƒë·ªô (r, c) (0-indexed) ƒë√£ gh√© thƒÉm
    clusters = []    # List ch·ª©a c√°c c·ª•m

    for r in range(rows):
        for c in range(cols):
            # N·∫øu √¥ n√†y l√† "ƒê·∫•t" (True) v√† ch∆∞a ƒë∆∞·ª£c gh√© thƒÉm
            if heatmap[r][c] and (r, c) not in visited:
                
                # B·∫Øt ƒë·∫ßu m·ªôt c·ª•m m·ªõi
                new_cluster = []
                q = deque([(r, c)]) # H√†ng ƒë·ª£i cho BFS
                visited.add((r, c))

                while q:
                    curr_r, curr_c = q.popleft()
                    # Th√™m t·ªça ƒë·ªô (0-indexed) v√†o c·ª•m
                    new_cluster.append((curr_r, curr_c))

                    # Ki·ªÉm tra 4 h∆∞·ªõng l√¢n c·∫≠n (tr√™n, d∆∞·ªõi, tr√°i, ph·∫£i)
                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                        nr, nc = curr_r + dr, curr_c + dc

                        # Ki·ªÉm tra xem c√≥ n·∫±m trong ranh gi·ªõi b·∫£n ƒë·ªì kh√¥ng
                        if 0 <= nr < rows and 0 <= nc < cols:
                            # N·∫øu √¥ l√¢n c·∫≠n l√† "ƒê·∫•t" v√† ch∆∞a gh√© thƒÉm
                            if heatmap[nr][nc] and (nr, nc) not in visited:
                                visited.add((nr, nc))
                                q.append((nr, nc))
                
                # Sau khi while k·∫øt th√∫c, th√™m c·ª•m m·ªõi v√†o danh s√°ch
                clusters.append(new_cluster)
                
    return clusters

# --- B∆Ø·ªöC 4: L·ªåC C·ª§M & L·∫§Y T·ªåA ƒê·ªò (BOUNDING BOX) ---
def _filter_and_get_boundaries(clusters: List[List[Tuple[int, int]]], 
                               min_width: int = 5, 
                               min_height: int = 3) -> List[Dict[str, int]]:
    """
    L·∫∑p qua c√°c c·ª•m, l·ªçc b·ªè "nhi·ªÖu" (c·ª•m qu√° nh·ªè),
    v√† tr·∫£ v·ªÅ t·ªça ƒë·ªô (bounding box) c·ªßa c√°c "b·∫£ng" h·ª£p l·ªá.
    
    T·ªça ƒë·ªô tr·∫£ v·ªÅ l√† 1-indexed (ƒë·ªÉ kh·ªõp v·ªõi Excel).
    """
    final_table_boundaries = []
    
    for cluster in clusters:
        if not cluster:
            continue
            
        # L·∫•y t·∫•t c·∫£ t·ªça ƒë·ªô (0-indexed) c·ªßa c·ª•m
        all_r = [r for r, c in cluster]
        all_c = [c for r, c in cluster]
        
        # T√¨m min/max (0-indexed)
        min_r, max_r = min(all_r), max(all_r)
        min_c, max_c = min(all_c), max(all_c)
        
        # T√≠nh to√°n k√≠ch th∆∞·ªõc
        width = max_c - min_c + 1
        height = max_r - min_r + 1
        
        # √Åp d·ª•ng b·ªô l·ªçc (heuristic)
        if width >= min_width and height >= min_height:
            
            # N·∫øu ƒë·ªß l·ªõn, l∆∞u l·∫°i t·ªça ƒë·ªô (chuy·ªÉn v·ªÅ 1-indexed)
            final_table_boundaries.append({
                'min_row': min_r + 1,
                'max_row': max_r + 1,
                'min_col': min_c + 1,
                'max_col': max_c + 1
            })
            
    return final_table_boundaries

# --- H√ÄM T·ªîNG H·ª¢P (MAIN FUNCTION) ---
def detect_tables(file_path: str, sheet_name: str, 
                  min_width: int = 5, 
                  min_height: int = 3) -> List[Dict[str, int]]:
    """
    Ph√°t hi·ªán t·∫•t c·∫£ c√°c "b·∫£ng" (ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b·∫±ng border)
    trong m·ªôt sheet Excel.
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel.
        sheet_name: T√™n sheet c·∫ßn x·ª≠ l√Ω.
        min_width: Chi·ªÅu r·ªông t·ªëi thi·ªÉu ƒë·ªÉ coi l√† 1 b·∫£ng (√Ω t∆∞·ªüng "line > 5").
        min_height: Chi·ªÅu cao t·ªëi thi·ªÉu ƒë·ªÉ coi l√† 1 b·∫£ng.
        
    Returns:
        M·ªôt list c√°c dict, m·ªói dict ch·ª©a t·ªça ƒë·ªô 1-indexed c·ªßa b·∫£ng.
        V√≠ d·ª•: [{'min_row': 2, 'max_row': 12, 'min_col': 1, 'max_col': 26}]
    """
    try:
        # data_only=True ƒë·ªÉ ƒë·ªçc gi√° tr·ªã (n·∫øu c·∫ßn), kh√¥ng ph·∫£i c√¥ng th·ª©c
        wb = openpyxl.load_workbook(file_path, data_only=True)
        if sheet_name not in wb.sheetnames:
            print(f"L·ªói: Kh√¥ng t√¨m th·∫•y sheet '{sheet_name}' trong file.")
            return []
        ws = wb[sheet_name]
    except Exception as e:
        print(f"L·ªói khi t·∫£i file ho·∫∑c sheet: {e}")
        return []

    # --- Ch·∫°y 4 b∆∞·ªõc c·ªßa Giai ƒëo·∫°n 1 ---
    
    # B∆∞·ªõc 1:
    print(f"B∆∞·ªõc 1: ƒêang t·∫°o b·∫£n ƒë·ªì √¥ g·ªôp...")
    merged_map = _create_merged_cell_map(ws)
    print(f"B∆∞·ªõc 1: Ho√†n th√†nh. T√¨m th·∫•y {len(merged_map)} √¥ con trong c√°c √¥ g·ªôp.")
    
    # B∆∞·ªõc 2:
    print(f"B∆∞·ªõc 2: ƒêang t·∫°o b·∫£n ƒë·ªì nhi·ªát border (c√≥ x·ª≠ l√Ω √¥ g·ªôp)...")
    heatmap = _create_border_heatmap(ws, merged_map)
    print("B∆∞·ªõc 2: Ho√†n th√†nh.")
    
    # B∆∞·ªõc 3:
    print(f"B∆∞·ªõc 3: ƒêang t√¨m c√°c c·ª•m border...")
    clusters = _find_clusters(heatmap)
    print(f"B∆∞·ªõc 3: Ho√†n th√†nh. T√¨m th·∫•y {len(clusters)} c·ª•m.")
    
    # B∆∞·ªõc 4:
    print(f"B∆∞·ªõc 4: ƒêang l·ªçc c·ª•m v√† l·∫•y t·ªça ƒë·ªô (min_width={min_width}, min_height={min_height})...")
    boundaries = _filter_and_get_boundaries(clusters, min_width, min_height)
    print(f"B∆∞·ªõc 4: Ho√†n th√†nh. T√¨m th·∫•y {len(boundaries)} b·∫£ng h·ª£p l·ªá.")
    
    wb.close()
    return boundaries







def debug_extract_data(file_path: str, sheet_name: str, 
                       boundary: Dict[str, int]) -> pd.DataFrame:
    """
    ƒê·ªçc v√† tr·∫£ v·ªÅ d·ªØ li·ªáu th√¥ (raw data) t·ª´ B√äN TRONG m·ªôt t·ªça ƒë·ªô (boundary)
    ƒë√£ ƒë∆∞·ª£c ph√°t hi·ªán, d√πng cho m·ª•c ƒë√≠ch ki·ªÉm tra (debug).
    
    T·ªça ƒë·ªô boundary nh·∫≠n v√†o l√† 1-indexed.
    """
    
    # 1. Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô 1-indexed (t·ª´ detect_tables) 
    #    sang 0-indexed (cho pandas)
    
    # H√†ng 3 (1-indexed) -> skiprows=2 (b·ªè qua h√†ng 0, 1)
    skip_rows = boundary['min_row'] - 1
    
    # S·ªë h√†ng c·∫ßn ƒë·ªçc
    num_rows = boundary['max_row'] - boundary['min_row'] + 1
    
    # C·ªôt 1 (1-indexed) -> c·ªôt 0 (0-indexed)
    # C·ªôt 26 (1-indexed) -> c·ªôt 25 (0-indexed)
    # Ch√∫ng ta c·∫ßn list [0, 1, ..., 25]
    cols_to_use = list(range(
        boundary['min_col'] - 1,  # (1-1) = 0
        boundary['max_col']       # (26) -> range() s·∫Ω d·ª´ng ·ªü 25
    ))
    
    if not cols_to_use:
        print("L·ªói: Kh√¥ng c√≥ c·ªôt n√†o ƒë·ªÉ ƒë·ªçc.")
        return pd.DataFrame()

    # 2. ƒê·ªçc file Excel ch·ªâ trong ph·∫°m vi ƒë√£ ƒë·ªãnh
    try:
        raw_table_df = pd.read_excel(
            file_path,
            sheet_name=sheet_name,
            header=None,        # Kh√¥ng gi·∫£ ƒë·ªãnh header, ƒë·ªçc th√¥
            skiprows=skip_rows,   # B·ªè qua c√°c h√†ng b√™n tr√™n
            nrows=num_rows,     # Ch·ªâ ƒë·ªçc s·ªë h√†ng c·ªßa b·∫£ng
            usecols=cols_to_use   # Ch·ªâ ƒë·ªçc c√°c c·ªôt c·ªßa b·∫£ng
        )
        
        # ƒê·∫∑t l·∫°i index c·ªôt ƒë·ªÉ d·ªÖ nh√¨n (0, 1, 2...)
        raw_table_df.columns = range(raw_table_df.shape[1])
        
        return raw_table_df
        
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t d·ªØ li·ªáu debug: {e}")
        return pd.DataFrame()
    

# ======================================================================
# GIAI ƒêO·∫†N 2: TR√çCH XU·∫§T JSON (Code m·ªõi)
# ======================================================================
import pandas as pd
import json
from typing import Dict, List, Any, Optional, Tuple
import re


class DynamicExcelParser:
    """
    Parser ƒë·ªông cho b·∫£ng Excel v·ªõi header nhi·ªÅu c·∫•p.
    T·ª± ƒë·ªông ph√°t hi·ªán c·∫•u tr√∫c v√† chuy·ªÉn ƒë·ªïi sang nested JSON.
    """
    
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.header_end_row = 0
        self.data_start_row = 0
        self.column_structure = []
        
    def parse(self) -> Dict[str, Any]:
        """Parse to√†n b·ªô DataFrame sang nested JSON."""
        
        # B∆∞·ªõc 1: T√¨m ranh gi·ªõi gi·ªØa header v√† data
        self._detect_header_boundary()
        
        # B∆∞·ªõc 2: Parse c·∫•u tr√∫c header
        self._parse_header_structure()
        
        # B∆∞·ªõc 3: Parse d·ªØ li·ªáu
        data_rows = self._parse_data_rows()
        
        return {
            "metadata": {
                "header_rows": self.header_end_row,
                "data_start_row": self.data_start_row,
                "total_columns": len(self.column_structure),
                "column_structure": self.column_structure
            },
            "data": data_rows
        }
    
    def _detect_header_boundary(self):
        """
        T·ª± ƒë·ªông ph√°t hi·ªán h√†ng n√†o l√† ranh gi·ªõi gi·ªØa header v√† data.
        S·ª≠ d·ª•ng heuristic: h√†ng ƒë·∫ßu ti√™n c√≥ pattern nh∆∞ ID-1, ID-2, ho·∫∑c ng√†y th√°ng th·ª±c.
        """
        
        for idx in range(len(self.df)):
            row = self.df.iloc[idx]
            
            # Ki·ªÉm tra c·ªôt th·ª© 2 (th∆∞·ªùng l√† ID)
            if pd.notna(row[1]):
                val = str(row[1]).strip()
                
                # Pattern: ID-s·ªë ho·∫∑c s·ªë thu·∫ßn t√∫y (kh√¥ng ph·∫£i text m√¥ t·∫£)
                if re.match(r'^ID-?\d+$', val, re.IGNORECASE) or \
                   (val.isdigit() and int(val) < 1000):  # ID d·∫°ng s·ªë nh·ªè
                    self.data_start_row = idx
                    self.header_end_row = idx
                    break
            
            # N·∫øu c√≥ nhi·ªÅu √¥ li√™n ti·∫øp ch·ª©a s·ªë (d·ªØ li·ªáu th·ª±c)
            numeric_count = sum(1 for v in row[2:] if self._is_numeric(v))
            if numeric_count > len(row) * 0.3:  # >30% l√† s·ªë
                self.data_start_row = idx
                self.header_end_row = idx
                break
        
        if self.header_end_row == 0:
            # Fallback: gi·∫£ s·ª≠ 5 h√†ng ƒë·∫ßu l√† header
            self.header_end_row = min(5, len(self.df) - 1)
            self.data_start_row = self.header_end_row
    
    def _is_numeric(self, val) -> bool:
        """Ki·ªÉm tra gi√° tr·ªã c√≥ ph·∫£i s·ªë kh√¥ng."""
        if pd.isna(val):
            return False
        try:
            float(val)
            return True
        except:
            return False
    
    def _parse_header_structure(self):
        """
        Parse c·∫•u tr√∫c header ƒë·ªông, t·ª± ƒë·ªông ph√°t hi·ªán c√°c nh√≥m v√† nh√≥m con.
        """
        
        header_rows = []
        for idx in range(self.header_end_row):
            header_rows.append(self.df.iloc[idx].values.tolist())
        
        if not header_rows:
            # Kh√¥ng c√≥ header, m·ªói c·ªôt l√† m·ªôt field ƒë∆°n gi·∫£n
            self.column_structure = [
                {"col_index": i, "path": [f"Column_{i}"], "name": f"Column_{i}"}
                for i in range(len(self.df.columns))
            ]
            return
        
        # Parse t·ª´ng c·ªôt
        num_cols = len(self.df.columns)
        
        for col_idx in range(num_cols):
            col_path = self._build_column_path(header_rows, col_idx)
            
            self.column_structure.append({
                "col_index": col_idx,
                "path": col_path,
                "name": col_path[-1] if col_path else f"Column_{col_idx}",
                "full_path": " > ".join(col_path)
            })
    
    def _build_column_path(self, header_rows: List[List], col_idx: int) -> List[str]:
        """
        X√¢y d·ª±ng path ph√¢n c·∫•p cho m·ªôt c·ªôt t·ª´ c√°c h√†ng header.
        
        Logic:
        - ƒê·ªçc t·ª´ tr√™n xu·ªëng d∆∞·ªõi
        - B·ªè qua NaN
        - Ph√°t hi·ªán merged cells (gi√° tr·ªã tr·∫£i d√†i nhi·ªÅu c·ªôt)
        - X√¢y d·ª±ng path: [Group] -> [SubGroup] -> [Column Name]
        """
        
        path = []
        
        for row_idx, row in enumerate(header_rows):
            val = row[col_idx]
            
            # B·ªè qua NaN
            if pd.isna(val):
                # Ki·ªÉm tra xem c√≥ ph·∫£i merged cell kh√¥ng (t√¨m gi√° tr·ªã g·∫ßn nh·∫•t b√™n tr√°i)
                merged_val = self._find_merged_value(row, col_idx)
                if merged_val:
                    # Ch·ªâ th√™m v√†o path n·∫øu ch∆∞a c√≥ (tr√°nh l·∫∑p)
                    if not path or path[-1] != merged_val:
                        path.append(merged_val)
                continue
            
            val_str = str(val).strip()
            
            # B·ªè qua c√°c gi√° tr·ªã r·ªóng ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát
            if not val_str or val_str in ['nan', 'NaN', 'None']:
                continue
            
            # Th√™m v√†o path n·∫øu ch∆∞a c√≥
            if not path or path[-1] != val_str:
                path.append(val_str)
        
        # N·∫øu path r·ªóng, ƒë·∫∑t t√™n m·∫∑c ƒë·ªãnh
        if not path:
            path = [f"Column_{col_idx}"]
        
        return path
    
    def _find_merged_value(self, row: List, col_idx: int) -> Optional[str]:
        """
        T√¨m gi√° tr·ªã c·ªßa merged cell b·∫±ng c√°ch t√¨m ng∆∞·ª£c v·ªÅ b√™n tr√°i.
        """
        
        for i in range(col_idx - 1, -1, -1):
            if pd.notna(row[i]):
                val = str(row[i]).strip()
                if val and val not in ['nan', 'NaN', 'None']:
                    return val
        
        return None
    
    def _parse_data_rows(self) -> List[Dict[str, Any]]:
        """Parse c√°c h√†ng d·ªØ li·ªáu th√†nh list of nested dictionaries."""
        
        data_rows = []
        
        for idx in range(self.data_start_row, len(self.df)):
            row = self.df.iloc[idx]
            
            # Ki·ªÉm tra h√†ng r·ªóng (t·∫•t c·∫£ ƒë·ªÅu NaN)
            if row.isna().all():
                continue
            
            row_data = self._parse_single_row(row)
            data_rows.append(row_data)
        
        return data_rows
    
    def _parse_single_row(self, row: pd.Series) -> Dict[str, Any]:
        """
        Parse m·ªôt h√†ng d·ªØ li·ªáu th√†nh nested dictionary d·ª±a tr√™n column_structure.
        """
        
        result = {}
        
        for col_info in self.column_structure:
            col_idx = col_info["col_index"]
            path = col_info["path"]
            value = self._safe_value(row[col_idx])
            
            # X√¢y d·ª±ng nested structure
            self._set_nested_value(result, path, value)
        
        return result
    
    def _set_nested_value(self, data: Dict, path: List[str], value: Any):
        """
        ƒê·∫∑t gi√° tr·ªã v√†o nested dictionary theo path.
        
        V√≠ d·ª•: path = ["Group1", "SubGroup", "Data"] 
               -> data["Group1"]["SubGroup"]["Data"] = value
        """
        
        if not path:
            return
        
        # N·∫øu path ch·ªâ c√≥ 1 ph·∫ßn t·ª≠, g√°n tr·ª±c ti·∫øp
        if len(path) == 1:
            data[path[0]] = value
            return
        
        # N·∫øu path c√≥ nhi·ªÅu ph·∫ßn t·ª≠, t·∫°o nested structure
        current = data
        
        for i, key in enumerate(path[:-1]):
            if key not in current:
                current[key] = {}
            elif not isinstance(current[key], dict):
                # Xung ƒë·ªôt: key ƒë√£ t·ªìn t·∫°i nh∆∞ng kh√¥ng ph·∫£i dict
                # Chuy·ªÉn th√†nh dict v√† gi·ªØ gi√° tr·ªã c≈©
                old_value = current[key]
                current[key] = {"_value": old_value}
            
            current = current[key]
        
        # ƒê·∫∑t gi√° tr·ªã cu·ªëi c√πng
        final_key = path[-1]
        current[final_key] = value
    
    def _safe_value(self, val: Any) -> Any:
        """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã an to√†n, x·ª≠ l√Ω NaN v√† ki·ªÉu d·ªØ li·ªáu."""
        
        if pd.isna(val):
            return None
        
        # Chuy·ªÉn numpy types sang Python native types
        if hasattr(val, 'item'):
            val = val.item()
        
        # X·ª≠ l√Ω s·ªë
        if isinstance(val, (int, float)):
            if isinstance(val, float):
                if val.is_integer():
                    return int(val)
            return val
        
        # X·ª≠ l√Ω chu·ªói
        val_str = str(val).strip()
        return val_str if val_str else None


def excel_to_nested_json(df: pd.DataFrame, 
                         output_file: Optional[str] = None,
                         indent: int = 2) -> Dict[str, Any]:
    """
    Chuy·ªÉn ƒë·ªïi DataFrame v·ªõi header nhi·ªÅu c·∫•p sang nested JSON.
    
    Function n√†y ho√†n to√†n ƒê·ªòNG - t·ª± ƒë·ªông ph√°t hi·ªán c·∫•u tr√∫c header.
    
    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame ƒë·ªçc t·ª´ Excel v·ªõi header=None
    output_file : str, optional
        ƒê∆∞·ªùng d·∫´n file JSON output. N·∫øu None, kh√¥ng ghi file.
    indent : int
        S·ªë space cho indentation trong JSON
        
    Returns:
    --------
    dict : Nested JSON structure
    
    Example:
    --------
    >>> import pandas as pd
    >>> df = pd.read_excel('data.xlsx', header=None)
    >>> result = excel_to_nested_json(df, 'output.json')
    >>> print(json.dumps(result, indent=2, ensure_ascii=False))
    """
    
    parser = DynamicExcelParser(df)
    result = parser.parse()
    
    # Ghi file n·∫øu ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=indent, ensure_ascii=False)
        print(f"‚úÖ ƒê√£ l∆∞u JSON v√†o: {output_file}")
        print(f"üìä S·ªë h√†ng d·ªØ li·ªáu: {len(result['data'])}")
        print(f"üìã S·ªë c·ªôt: {result['metadata']['total_columns']}")
    
    return result


def visualize_structure(result: Dict[str, Any]) -> None:
    """
    In ra c·∫•u tr√∫c c·ªôt ƒë·ªÉ ki·ªÉm tra.
    """
    print("\n" + "="*80)
    print("C·∫§U TR√öC C·ªòT ƒê∆Ø·ª¢C PH√ÅT HI·ªÜN")
    print("="*80)
    
    for col in result['metadata']['column_structure']:
        print(f"C·ªôt {col['col_index']:2d}: {col['full_path']}")
    
    print("\n" + "="*80)
    print(f"T·ªïng s·ªë c·ªôt: {result['metadata']['total_columns']}")
    print(f"S·ªë h√†ng header: {result['metadata']['header_rows']}")
    print(f"S·ªë h√†ng d·ªØ li·ªáu: {len(result['data'])}")
    print("="*80 + "\n")



# --- [GIAI ƒêO·∫†N 2: PARSE LOGIC - H√ÄM M·ªöI] ---

def detect_header_split_point(
    raw_table_df: pd.DataFrame, 
    worksheet: Worksheet,
    boundary: Dict[str, int],
    border_threshold: float = 0.95  # Gi√° tr·ªã t·ª´ 0.0 ƒë·∫øn 1.0
) -> int:
    """
    Ph√°t hi·ªán header b·∫±ng c√°ch t√¨m ƒê∆Ø·ªúNG K·∫∫ NGANG CU·ªêI C√ôNG k√©o d√†i su·ªët b·∫£ng.
    
    Logic:
    1. B·ªè qua h√†ng ƒë·∫ßu ti√™n (vi·ªÅn tr√™n c·ªßa table)
    2. Qu√©t T·∫§T C·∫¢ c√°c h√†ng v√† t√¨m h√†ng CU·ªêI C√ôNG c√≥ k·∫ª ngang >= threshold
    3. H√†ng ƒë√≥ l√† ranh gi·ªõi header/data
    
    Args:
        border_threshold: T·ª∑ l·ªá t·ª´ 0.0 ƒë·∫øn 1.0 (VD: 0.95 = 95%, 1.0 = 100%)
    
    Returns:
        Index (0-based) c·ªßa h√†ng DATA ƒë·∫ßu ti√™n. Tr·∫£ v·ªÅ -1 n·∫øu kh√¥ng t√¨m th·∫•y.
    """
    
    # Validate threshold
    if not 0 <= border_threshold <= 1:
        print(f"‚ö† C·∫¢NH B√ÅO: border_threshold ph·∫£i t·ª´ 0.0 ƒë·∫øn 1.0, nh·∫≠n ƒë∆∞·ª£c: {border_threshold}")
        border_threshold = max(0.0, min(1.0, border_threshold))
    
    total_columns = raw_table_df.shape[1]
    if total_columns == 0:
        return -1

    total_rows = raw_table_df.shape[0]
    if total_rows <= 1:
        return -1

    print(f"[detect_header_split_point] Qu√©t {total_rows} h√†ng, {total_columns} c·ªôt")
    print(f"  Threshold: {border_threshold} ({border_threshold*100:.1f}%)")
    print(f"  S·ªë cells t·ªëi thi·ªÉu: {int(border_threshold * total_columns)}/{total_columns}\n")

    last_border_row = -1
    
    # Qu√©t t·ª´ h√†ng 1 (b·ªè h√†ng 0 - vi·ªÅn tr√™n)
    for r_idx in range(1, total_rows):
        real_row_num = boundary['min_row'] + r_idx
        horizontal_count = 0
        
        # ƒê·∫øm cells c√≥ border TOP
        for c_idx in range(boundary['min_col'], boundary['max_col'] + 1):
            cell = worksheet.cell(row=real_row_num, column=c_idx)
            
            if cell.border.top and cell.border.top.style and cell.border.top.style != 'none':
                horizontal_count += 1
        
        border_rate = horizontal_count / total_columns
        
        # In k·∫øt qu·∫£
        status = ""
        if border_rate >= border_threshold:
            last_border_row = r_idx
            status = " ‚úì ·ª®NG VI√äN"
        
        print(f"  H√†ng {r_idx:2d} (Excel {real_row_num:2d}): "
              f"{horizontal_count:2d}/{total_columns:2d} = "
              f"{border_rate:5.1%}{status}")
    
        # K·∫øt lu·∫≠n
        if last_border_row != -1:
            print(f"\n‚úì Ranh gi·ªõi t·∫°i h√†ng {last_border_row}")
            print(f"  Header: 0-{last_border_row-1}, Data: {last_border_row}+")
            return last_border_row
    
    print(f"\n‚úó Kh√¥ng t√¨m th·∫•y h√†ng n√†o >= {border_threshold*100:.0f}%")
    return -1


def detect_attribute_boundary(header_df: pd.DataFrame) -> Tuple[List[int], List[int]]:
    """
    (H√†m M·ªöI - B∆∞·ªõc 2.5)
    Ph√¢n t√≠ch `header_df` (C√°i Khu√¥n) ƒë·ªÉ t√¨m "Ranh gi·ªõi Thu·ªôc t√≠nh".
    
    Quy t·∫Øc (Heuristic):
    - "C·ªôt Thu·ªôc t√≠nh" (Ng√†y, ID) ch·ªâ c√≥ gi√° tr·ªã ·ªü h√†ng ƒë·∫ßu ti√™n (index 0).
    - "C·ªôt D·ªØ li·ªáu" (Group 1) c√≥ gi√° tr·ªã ·ªü c·∫£ h√†ng 0 V√Ä c√°c h√†ng d∆∞·ªõi.
    - Ranh gi·ªõi l√† c·ªôt "D·ªØ li·ªáu" ƒë·∫ßu ti√™n ƒë∆∞·ª£c t√¨m th·∫•y.
    
    Returns:
        M·ªôt tuple ch·ª©a 2 list: (attribute_cols_idx, data_cols_idx)
    """
    print(f"\n[detect_attribute_boundary] Ph√¢n t√≠ch {header_df.shape[1]} c·ªôt header...")
    
    attribute_cols_idx = []
    data_cols_idx = []
    
    total_header_rows = header_df.shape[0]
    total_cols = header_df.shape[1]

    # Tr∆∞·ªùng h·ª£p B·∫£ng ƒê∆°n gi·∫£n (header_df ch·ªâ c√≥ 1 h√†ng)
    if total_header_rows == 1:
        print("  -> Ph√°t hi·ªán B·∫£ng ƒê∆°n gi·∫£n (1 h√†ng header).")
        # Gi·∫£ ƒë·ªãnh: C·ªôt ƒë·∫ßu ti√™n l√† Thu·ªôc t√≠nh, c√≤n l·∫°i l√† D·ªØ li·ªáu
        attribute_cols_idx = [0]
        data_cols_idx = list(range(1, total_cols))
        
        print(f"  -> C·ªôt Thu·ªôc t√≠nh: {attribute_cols_idx}")
        print(f"  -> C·ªôt D·ªØ li·ªáu: {data_cols_idx}")
        return attribute_cols_idx, data_cols_idx

    # Tr∆∞·ªùng h·ª£p B·∫£ng Ph·ª©c t·∫°p (header_df c√≥ > 1 h√†ng)
    print("  -> Ph√°t hi·ªán B·∫£ng Ph·ª©c t·∫°p (>1 h√†ng header).")
    
    for c_idx in header_df.columns:
        # L·∫•y "th√¢n" c·ªßa c·ªôt (t·∫•t c·∫£ c√°c h√†ng TR·ª™ h√†ng ƒë·∫ßu ti√™n)
        column_body = header_df.iloc[1: , c_idx]
        
        # Ki·ªÉm tra xem "th√¢n" c√≥ d·ªØ li·ªáu (kh√¥ng ph·∫£i to√†n NaN) kh√¥ng
        body_has_data = not column_body.isna().all()
        
        if body_has_data:
            # ƒê√¢y l√† ranh gi·ªõi! C·ªôt n√†y l√† "C·ªôt D·ªØ li·ªáu" ƒë·∫ßu ti√™n.
            print(f"  -> Ranh gi·ªõi t·∫°i C·ªôt {c_idx} (v√¨ c√≥ '{column_body.loc[column_body.notna().idxmax()]}')")
            
            # T·∫•t c·∫£ c√°c c·ªôt t·ª´ ƒë√¢y v·ªÅ sau ƒê·ªÄU L√Ä C·ªôt D·ªØ li·ªáu
            data_cols_idx = list(range(c_idx, total_cols))
            
            # Tho√°t v√≤ng l·∫∑p
            break
        else:
            # N·∫øu "th√¢n" to√†n NaN, ƒë√¢y l√† "C·ªôt Thu·ªôc t√≠nh"
            print(f"  -> C·ªôt {c_idx} ('{header_df.iloc[0, c_idx]}') l√† C·ªôt Thu·ªôc t√≠nh.")
            attribute_cols_idx.append(c_idx)

    print(f"\n  -> [CH·ªêT] C·ªôt Thu·ªôc t√≠nh: {attribute_cols_idx}")
    print(f"  -> [CH·ªêT] C·ªôt D·ªØ li·ªáu: {data_cols_idx}")
    return attribute_cols_idx, data_cols_idx


# --- [GIAI ƒêO·∫†N 3: Tr√≠ch xu·∫•t JSON] ---


def _set_nested_value(target_dict: Dict, path: List[str], value: Any):
    """
    (H√†m tr·ª£ gi√∫p - B√°nh xe)
    ƒêi theo `path` v√† g√°n `value` ·ªü c·∫•p cu·ªëi c√πng.
    V√≠ d·ª•: _set_nested_value(d, ['Group 1', 'Sub 1'], 5)
    -> d['Group 1']['Sub 1'] = 5
    """
    for key in path[:-1]:
        # N·∫øu key ch∆∞a c√≥, t·∫°o 1 dict con
        target_dict = target_dict.setdefault(key, {})
    # G√°n gi√° tr·ªã ·ªü c·∫•p cu·ªëi c√πng
    target_dict[path[-1]] = value


def _build_header_map(header_df: pd.DataFrame, data_cols: List[int]) -> Dict[int, List[str]]:
    """
    (H√†m M·ªöI - B∆∞·ªõc 2.3)
    Ph√¢n t√≠ch `header_df` v√† t·∫°o "B·∫£n ƒë·ªì Header" cho c√°c c·ªôt d·ªØ li·ªáu.
    
    Logic:
    1. L·∫•p ƒë·∫ßy (ffill) c√°c √¥ g·ªôp (c·∫£ ngang v√† d·ªçc).
    2. ƒê·ªçc "d·ªçc" t·ª´ng c·ªôt ƒë·ªÉ x√¢y d·ª±ng "con ƒë∆∞·ªùng" (path).
    
    Returns:
        M·ªôt dict (b·∫£n ƒë·ªì): { column_index -> [path, to, header] }
        V√≠ d·ª•: { 5: ['(Group 1)', 'Sub-Group 1.1', 'F-Data'] }
    """
    print(f"\n[build_header_map] ƒêang x√¢y d·ª±ng b·∫£n ƒë·ªì cho {len(data_cols)} c·ªôt d·ªØ li·ªáu...")
    
    # 1. L·∫•p ƒë·∫ßy (ffill) ƒë·ªÉ x·ª≠ l√Ω √¥ g·ªôp
    # Fill ngang (axis=1) ƒë·ªÉ v√° c√°c l·ªó h·ªïng √¥ g·ªôp
    header_df_filled = header_df.ffill(axis=1)
    # Fill d·ªçc (axis=0) ƒë·ªÉ l·∫•p ƒë·∫ßy c√°c c·∫•p (v√≠ d·ª•: Sub-Group 1.1)
    header_df_filled = header_df_filled.ffill(axis=0)
    
    header_map = {}
    
    # Ch·ªâ l·∫∑p qua c√°c C·ªòT D·ªÆ LI·ªÜU
    for c_idx in data_cols:
        path = []
        last_val = None # D√πng ƒë·ªÉ tr√°nh l·∫∑p l·∫°i (v√≠ d·ª•: Group 1, Group 1, Group 1...)
        
        # L·∫∑p qua t·ª´ng h√†ng (row_index) trong header_df
        for r_idx in header_df_filled.index:
            value = header_df_filled.loc[r_idx, c_idx]
            
            # Ch·ªâ th√™m n·∫øu n√≥ kh√¥ng NaN V√Ä kh√¥ng b·ªã l·∫∑p l·∫°i
            if pd.notna(value) and value != last_val:
                path.append(value)
                last_val = value
        
        header_map[c_idx] = path
    
    # print(f"  -> B·∫£n ƒë·ªì Header (m·∫´u): C·ªôt 5 -> {header_map.get(5)}")
    return header_map

def parse_table_to_long_json(
    header_df: pd.DataFrame, 
    data_df: pd.DataFrame, 
    attribute_cols: List[int], 
    data_cols: List[int]
) -> List[Dict[str, Any]]:
    """
    (H√†m M·ªöI - B∆∞·ªõc 2.4)
    L·∫Øp r√°p JSON theo ƒë·ªãnh d·∫°ng "D√†i" (Long Format)
    (M·ªôt object JSON cho m·ªói √î d·ªØ li·ªáu).
    """
    
    final_json_list = []
    
    # --- 1. Chu·∫©n b·ªã 2 "B·∫£n ƒë·ªì" ---
    
    # B·∫£n ƒë·ªì 1: "B·∫£n ƒë·ªì Header" (Tra c·ª©u Path theo C·ªôt)
    header_map = _build_header_map(header_df, data_cols)
    
    # B·∫£n ƒë·ªì 2: "T√™n Thu·ªôc t√≠nh" (L·∫•y t√™n "Ng√†y", "ID" t·ª´ h√†ng ƒë·∫ßu)
    attribute_key_names = [header_df.iloc[0, c_idx] for c_idx in attribute_cols]
    
    print(f"[parse_table_to_long_json] ƒêang l·∫Øp r√°p c√°c √¥...")

    # --- 2. V√≤ng l·∫∑p K√©p (L·∫Øp r√°p √î) ---
    
    # L·∫∑p qua c√°c H√ÄNG D·ªÆ LI·ªÜU (v√≠ d·ª•: index 5, 6)
    for r_idx in data_df.index:
        
        # a. L·∫•y "B·∫£n ghi Thu·ªôc t√≠nh" (Attribute Record) cho h√†ng n√†y
        # (L·∫•y 1 l·∫ßn cho m·ªói h√†ng)
        base_record = {}
        for i, c_idx in enumerate(attribute_cols):
            key = attribute_key_names[i]
            value = data_df.loc[r_idx, c_idx]
            base_record[key] = value
        
        # b. L·∫∑p qua c√°c C·ªòT D·ªÆ LI·ªÜU (v√≠ d·ª•: 2, 3, ..., 25)
        for c_idx in data_cols:
            
            # i. L·∫•y Gi√° tr·ªã (Value)
            value = data_df.loc[r_idx, c_idx]
            
            # B·ªè qua n·∫øu √¥ ƒë√≥ tr·ªëng (kh√¥ng t·∫°o JSON cho √¥ NaN)
            if pd.isna(value):
                continue
                
            # ii. L·∫•y "Con ƒë∆∞·ªùng" (Path)
            path = header_map[c_idx]
            
            # iii. L·∫Øp r√°p
            
            # T·∫°o b·∫£n sao c·ªßa "B·∫£n ghi Thu·ªôc t√≠nh"
            record = base_record.copy() 
            
            # T·∫°o object l·ªìng nhau (Keys)
            nested_data_obj = {}
            _set_nested_value(nested_data_obj, path, value)
            
            # G·ªôp 2 ph·∫ßn l·∫°i
            record.update(nested_data_obj)
            
            # Th√™m v√†o k·∫øt qu·∫£ cu·ªëi c√πng
            final_json_list.append(record)
            
    return final_json_list


if __name__ == "__main__":

# ======================================================================
# GIAI ƒêO·∫†N TEST 1: PH√ÅT HI·ªÜN B·∫¢NG
# ======================================================================

    # # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y cho ƒë√∫ng v·ªõi file c·ªßa b·∫°n
    # # FILE_PATH = "path/to/your/image_b9d51d.xlsx"
    # FILE_PATH = "Book1.xlsx" # Gi·∫£ s·ª≠ file t√™n l√† report.xlsx
    # SHEET_NAME = "Sheet1"     # Thay t√™n sheet n·∫øu c·∫ßn

    # print(f"--- B·∫Øt ƒë·∫ßu ph√°t hi·ªán b·∫£ng trong file: {FILE_PATH} ---")
    
    # # B·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh 'min_width' v√† 'min_height'
    # table_coordinates = detect_tables(
    #     FILE_PATH, 
    #     SHEET_NAME, 
    #     min_width=2, 
    #     min_height=2
    # )
    
    # print("\n--- K·∫æT QU·∫¢ CU·ªêI C√ôNG ---")
    # if table_coordinates:
    #     for i, coords in enumerate(table_coordinates):
    #         print(f"B·∫£ng {i+1} t√¨m th·∫•y t·∫°i (1-indexed):")
    #         print(f"  - H√†ng: t·ª´ {coords['min_row']} ƒë·∫øn {coords['max_row']}")
    #         print(f"  - C·ªôt:  t·ª´ {coords['min_col']} ƒë·∫øn {coords['max_col']}")
    # else:
    #     print("Kh√¥ng t√¨m th·∫•y b·∫£ng n√†o h·ª£p l·ªá.")




# ======================================================================
# GIAI ƒêO·∫†N TEST 2: PH√ÅT HI·ªÜN B·∫¢NG V√Ä TR√çCH XU·∫§T D·ªÆ LI·ªÜU 
# ======================================================================

    # FILE_PATH = "basic_test.xlsx" # S·ª≠a l·∫°i t√™n file c·ªßa b·∫°n
    # SHEET_NAME = "Sheet1"    # S·ª≠a l·∫°i t√™n sheet c·ªßa b·∫°n

    # print(f"--- B·∫Øt ƒë·∫ßu ph√°t hi·ªán b·∫£ng trong file: {FILE_PATH} ---")
    
    # table_coordinates = detect_tables(
    #     FILE_PATH, 
    #     SHEET_NAME, 
    #     min_width=2,  # Gi·ªØ nguy√™n min_width=2, min_height=2 nh∆∞ b·∫°n test
    #     min_height=2
    # )
    
    # print("\n--- K·∫æT QU·∫¢ CU·ªêI C√ôNG (PH√ÅT HI·ªÜN) ---")
    # if table_coordinates:
    #     for i, coords in enumerate(table_coordinates):
    #         print(f"B·∫£ng {i+1} t√¨m th·∫•y t·∫°i (1-indexed):")
    #         print(f"  - H√†ng: t·ª´ {coords['min_row']} ƒë·∫øn {coords['max_row']}")
    #         print(f"  - C·ªôt:  t·ª´ {coords['min_col']} ƒë·∫øn {coords['max_col']}")
            
    #         # --- PH·∫¶N DEBUG M·ªöI ---
    #         print(f"\n[DEBUG] ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu th√¥ B·∫£ng {i+1}...")
    #         raw_data = debug_extract_data(FILE_PATH, SHEET_NAME, coords)
    #         print(type(raw_data))
    #         print(raw_data)
    #         if not raw_data.empty:
    #             print(f"--- D·ªØ li·ªáu th√¥ B·∫£ng {i+1} (ƒë·∫ßu & cu·ªëi): ---")
    #             # Hi·ªÉn th·ªã 5 h√†ng ƒë·∫ßu v√† 5 h√†ng cu·ªëi c·ªßa b·∫£ng
    #         #     with pd.option_context('display.max_rows', 10, 'display.max_columns', None):
    #         #         print(raw_data.head())
    #         # print("-" * 30)
    #         # --- K·∫æT TH√öC PH·∫¶N DEBUG --- 
            
    # else:
    #     print("Kh√¥ng t√¨m th·∫•y b·∫£ng n√†o h·ª£p l·ªá.")



# ======================================================================
# GIAI ƒêO·∫†N TEST 3: PH√ÅT HI·ªÜN HEADER V√Ä T√ÅCH D·ªÆ LI·ªÜU 
# ======================================================================


    # FILE_PATH = "basic_test.xlsx" # File test c·ªßa b·∫°n
    # SHEET_NAME = "basic3"         # Sheet c·ªßa b·∫°n

    # # --- PH·∫¢I LOAD `worksheet` TR∆Ø·ªöC ---
    # try:
    #     wb = openpyxl.load_workbook(FILE_PATH, data_only=True)
    #     if SHEET_NAME not in wb.sheetnames:
    #         raise ValueError(f"Kh√¥ng t√¨m th·∫•y sheet '{SHEET_NAME}'")
    #     worksheet = wb[SHEET_NAME]
    # except Exception as e:
    #     print(f"L·ªói khi t·∫£i workbook: {e}")
    #     exit()

    # # --- CH·∫†Y GIAI ƒêO·∫†N 1 (ƒê·ªÇ L·∫§Y ƒê·∫¶U V√ÄO) ---
    # print(f"--- [GIAI ƒêO·∫†N 1] ƒêang ch·∫°y detect_tables... ---")
    # table_coordinates = detect_tables(
    #     FILE_PATH, 
    #     SHEET_NAME, 
    #     min_width=2,
    #     min_height=2
    # )
    # print(f"--- [GIAI ƒêO·∫†N 1] Ho√†n th√†nh: T√¨m th·∫•y {len(table_coordinates)} b·∫£ng ---")

    # # L·∫∑p qua c√°c b·∫£ng t√¨m ƒë∆∞·ª£c
    # for i, coords in enumerate(table_coordinates):
    #     print(f"\n--- X·ª≠ l√Ω B·∫£ng {i+1} (H√†ng {coords['min_row']}->{coords['max_row']}) ---")
        
    #     raw_table_df = debug_extract_data(FILE_PATH, SHEET_NAME, coords)
        
    #     if raw_table_df.empty:
    #         continue
        
    #     # --- CH·∫†Y H√ÄM M·ªöI (CH·ªà D√ôNG BORDER) ---
    #     split_point_index = detect_header_split_point(
    #         raw_table_df, 
    #         worksheet,   # Truy·ªÅn worksheet
    #         coords,      # Truy·ªÅn t·ªça ƒë·ªô
    #         border_threshold=0.95 # Ch·ªâ truy·ªÅn ng∆∞·ª°ng border
    #     )
    #     # ---
        
    #     if split_point_index != -1:
    #         # Ki·ªÉm tra tr∆∞·ªùng h·ª£p ranh gi·ªõi v∆∞·ª£t qu√° s·ªë h√†ng (hi·∫øm g·∫∑p)
    #         if split_point_index >= len(raw_table_df.index):
    #              print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1}: Ranh gi·ªõi ({split_point_index}) v∆∞·ª£t qu√° s·ªë h√†ng. B·∫£ng c√≥ th·ªÉ ch·ªâ c√≥ Header.")
    #              continue

    #         print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1} ---")
    #         print(f"  -> Ranh gi·ªõi (Split Point) t√¨m th·∫•y t·∫°i index h√†ng: {split_point_index}")
            
    #         header_df = raw_table_df.iloc[0 : split_point_index]
    #         data_df = raw_table_df.iloc[split_point_index : ]
            
    #         print("\n  -> [KH·ªêI HEADER] (Keys):")
    #         print(header_df)
    #         print("\n  -> [KH·ªêI D·ªÆ LI·ªÜU] (Values):")
    #         print(data_df)
    #         print("-" * 30)
            
    #     else:
    #         print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1}: Kh√¥ng th·ªÉ x√°c ƒë·ªãnh ranh gi·ªõi Header/Data ---")

    # wb.close() # ƒê√≥ng workbook sau khi xong


# ======================================================================
# GIAI ƒêO·∫†N TEST 4: T√ÅCH THU·ªòC T√çNH TRONG HEADER V√Ä IN K·∫æT QU·∫¢ 
# ======================================================================

    
    # FILE_PATH = "basic_test.xlsx" # File test c·ªßa b·∫°n
    # SHEET_NAME = "basic3"         # Sheet c·ªßa b·∫°n

    # # --- PH·∫¢I LOAD `worksheet` TR∆Ø·ªöC ---
    # try:
    #     wb = openpyxl.load_workbook(FILE_PATH, data_only=True)
    #     if SHEET_NAME not in wb.sheetnames:
    #         raise ValueError(f"Kh√¥ng t√¨m th·∫•y sheet '{SHEET_NAME}'")
    #     worksheet = wb[SHEET_NAME]
    # except Exception as e:
    #     print(f"L·ªói khi t·∫£i workbook: {e}")
    #     exit()

    # # --- CH·∫†Y GIAI ƒêO·∫†N 1 (ƒê·ªÇ L·∫§Y ƒê·∫¶U V√ÄO) ---
    # print(f"--- [GIAI ƒêO·∫†N 1] ƒêang ch·∫°y detect_tables... ---")
    # table_coordinates = detect_tables(
    #     FILE_PATH, 
    #     SHEET_NAME, 
    #     min_width=2,
    #     min_height=2
    # )
    # print(f"--- [GIAI ƒêO·∫†N 1] Ho√†n th√†nh: T√¨m th·∫•y {len(table_coordinates)} b·∫£ng ---")

    # # L·∫∑p qua c√°c b·∫£ng t√¨m ƒë∆∞·ª£c
    # for i, coords in enumerate(table_coordinates):
    #     print(f"\n--- X·ª≠ l√Ω B·∫£ng {i+1} (H√†ng {coords['min_row']}->{coords['max_row']}) ---")
        
    #     raw_table_df = debug_extract_data(FILE_PATH, SHEET_NAME, coords)
        
    #     if raw_table_df.empty:
    #         continue
        
    #     # --- B∆Ø·ªöC 2.1: T√åM RANH GI·ªöI HEADER/DATA (H√†m c·ªßa b·∫°n) ---
    #     split_point_index = detect_header_split_point(
    #         raw_table_df, 
    #         worksheet,   # Truy·ªÅn worksheet
    #         coords,      # Truy·ªÅn t·ªça ƒë·ªô
    #         border_threshold=0.95 # Ch·ªâ truy·ªÅn ng∆∞·ª°ng border
    #     )
        
    #     if split_point_index != -1:
    #         if split_point_index >= len(raw_table_df.index):
    #              print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1}: Ranh gi·ªõi ({split_point_index}) v∆∞·ª£t qu√° s·ªë h√†ng.")
    #              continue

    #         print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1}: T√°ch Kh·ªëi ---")
    #         print(f"  -> Ranh gi·ªõi (Split Point) t√¨m th·∫•y t·∫°i index h√†ng: {split_point_index}")
            
    #         header_df = raw_table_df.iloc[0 : split_point_index]
    #         data_df = raw_table_df.iloc[split_point_index : ]
            
    #         print("\n  -> [KH·ªêI HEADER] (Keys):")
    #         print(header_df.head()) # In 5 d√≤ng ƒë·∫ßu
            
    #         # --- B∆Ø·ªöC 2.2: T√åM RANH GI·ªöI THU·ªòC T√çNH (H√†m M·ªöI) ---
    #         attribute_cols, data_cols = detect_attribute_boundary(header_df)
            
    #         print("-" * 30)
            
    #     else:
    #         print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1}: Kh√¥ng th·ªÉ x√°c ƒë·ªãnh ranh gi·ªõi Header/Data ---")

    # wb.close() # ƒê√≥ng workbook sau khi xong

# ======================================================================
# GIAI ƒêO·∫†N TEST 5: CH·∫†Y TO√ÄN B·ªò V√Ä IN K·∫æT QU·∫¢ JSON
# ======================================================================

    
    FILE_PATH = "Book1.xlsx" # File test c·ªßa b·∫°n
    # SHEET_NAME = "basic3"         # Sheet c·ªßa b·∫°n
    SHEET_NAME = "Sheet1"         # Sheet c·ªßa b·∫°n

    # --- PH·∫¢I LOAD `worksheet` TR∆Ø·ªöC ---
    try:
        wb = openpyxl.load_workbook(FILE_PATH, data_only=True)
        if SHEET_NAME not in wb.sheetnames:
            raise ValueError(f"Kh√¥ng t√¨m th·∫•y sheet '{SHEET_NAME}'")
        worksheet = wb[SHEET_NAME]
    except Exception as e:
        print(f"L·ªói khi t·∫£i workbook: {e}")
        exit()

    # --- CH·∫†Y GIAI ƒêO·∫†N 1 (ƒê·ªÇ L·∫§Y ƒê·∫¶U V√ÄO) ---
    print(f"--- [GIAI ƒêO·∫†N 1] ƒêang ch·∫°y detect_tables... ---")
    table_coordinates = detect_tables(
        FILE_PATH, 
        SHEET_NAME, 
        min_width=2,
        min_height=2
    )
    print(f"--- [GIAI ƒêO·∫†N 1] Ho√†n th√†nh: T√¨m th·∫•y {len(table_coordinates)} b·∫£ng ---")

    all_parsed_data = [] # List cu·ªëi c√πng ch·ª©a T·∫§T C·∫¢ JSON

    # L·∫∑p qua c√°c b·∫£ng t√¨m ƒë∆∞·ª£c
    for i, coords in enumerate(table_coordinates):
        print(f"\n--- X·ª≠ l√Ω B·∫£ng {i+1} (H√†ng {coords['min_row']}->{coords['max_row']}) ---")
        
        raw_table_df = debug_extract_data(FILE_PATH, SHEET_NAME, coords)
        
        if raw_table_df.empty:
            continue
        
        # --- B∆Ø·ªöC 2.1: T√åM RANH GI·ªöI HEADER/DATA (H√†m c·ªßa b·∫°n) ---
        split_point_index = detect_header_split_point(
            raw_table_df, 
            worksheet,
            coords,
            border_threshold=0.95
        )
        
        if split_point_index != -1:
            if split_point_index >= len(raw_table_df.index):
                 print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1}: Ranh gi·ªõi ({split_point_index}) v∆∞·ª£t qu√° s·ªë h√†ng.")
                 continue

            header_df = raw_table_df.iloc[0 : split_point_index]
            data_df = raw_table_df.iloc[split_point_index : ]
            
            # --- B∆Ø·ªöC 2.2: T√åM RANH GI·ªöI THU·ªòC T√çNH (H√†m M·ªöI) ---
            attribute_cols, data_cols = detect_attribute_boundary(header_df)
            
            # --- B∆Ø·ªöC 2.3 & 2.4: L·∫ÆP R√ÅP JSON ---
            try:
                # Ch·∫°y h√†m parse JSON (ƒê·ªãnh d·∫°ng "D√†i")
                json_output = parse_table_to_long_json(
                    header_df, 
                    data_df, 
                    attribute_cols, 
                    data_cols
                )
                
                all_parsed_data.extend(json_output)
                print(f"\n--- [GIAI ƒêO·∫†N 2] Parse B·∫£ng {i+1} th√†nh c√¥ng. T·∫°o ra {len(json_output)} b·∫£n ghi JSON.")

            except Exception as e:
                print(f"L·ªñI khi parse B·∫£ng {i+1}: {e}")
                import traceback
                traceback.print_exc()

            print("-" * 30)
            
        else:
            print(f"\n--- K·∫øt qu·∫£ B·∫£ng {i+1}: Kh√¥ng th·ªÉ x√°c ƒë·ªãnh ranh gi·ªõi Header/Data ---")

    wb.close() # ƒê√≥ng workbook sau khi xong
    
    print("\n--- [HO√ÄN TH√ÄNH] ƒê√£ x·ª≠ l√Ω t·∫•t c·∫£ c√°c b·∫£ng. ---")
    
    # In to√†n b·ªô k·∫øt qu·∫£ cu·ªëi c√πng
    print("\n--- T·ªîNG K·∫æT JSON ---")
    json_response = json.dumps(all_parsed_data, indent=2, ensure_ascii=False)

    ## Save to file
    OUTPUT_FILE = "final_output_test.json"
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(json_response)
    print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ JSON v√†o: {OUTPUT_FILE}")